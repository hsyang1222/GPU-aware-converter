{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmri.data.mri_data import fetch_dir\n",
    "from fastmri.data.subsample import create_mask_for_mask_type\n",
    "from fastmri.data.transforms import UnetDataTransform\n",
    "from fastmri.pl_modules import FastMriDataModule, UnetModule\n",
    "from fastmri.data import transforms, mri_data\n",
    "import pathlib\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "CHALLENGE = 'singlecoil'\n",
    "MASK_TYPE = 'random'\n",
    "center_fractions = [0.08]\n",
    "accelerations = [4]\n",
    "\n",
    "\n",
    "mask = create_mask_for_mask_type(\n",
    "        MASK_TYPE, center_fractions, accelerations\n",
    "    )\n",
    "\n",
    "train_transform = UnetDataTransform(CHALLENGE, mask_func=mask, use_seed=False)\n",
    "\n",
    "dataset = mri_data.SliceDataset(\n",
    "    root=pathlib.Path(\n",
    "      './fastmri_data/singlecoil_val'\n",
    "    ),\n",
    "    transform=train_transform,\n",
    "    challenge='singlecoil'\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=10)\n",
    "image, target, _, _, _, _, _ = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import InvertCnnConverter\n",
    "import torch\n",
    "import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'InvertCnnConverter' from '/home/hsyang/workspace/20210411_SYS/memcnn-unet/InvertCnnConverter.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(InvertCnnConverter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_model = Unet.UNet(n_channels=1, n_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (inc): CheckpointModule(\n",
      "    (module): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): UpInvertibleBlock(\n",
      "          (upscale): Upsample(scale_factor=(8.0, 8.0), mode=bilinear)\n",
      "          (conv2): InvertibleModuleWrapper(\n",
      "            (_fn): AdditiveCoupling(\n",
      "              (Gm): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (Fm): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): InvertibleModuleWrapper(\n",
      "          (_fn): AdditiveCoupling(\n",
      "            (Gm): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (Fm): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down1): CheckpointModule(\n",
      "    (module): Down(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): UpInvertibleBlock(\n",
      "              (upscale): Upsample(scale_factor=(2.0, 1.0), mode=bilinear)\n",
      "              (conv2): InvertibleModuleWrapper(\n",
      "                (_fn): AdditiveCoupling(\n",
      "                  (Gm): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (Fm): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): InvertibleModuleWrapper(\n",
      "              (_fn): AdditiveCoupling(\n",
      "                (Gm): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (Fm): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down2): CheckpointModule(\n",
      "    (module): Down(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): UpInvertibleBlock(\n",
      "              (upscale): Upsample(scale_factor=(2.0, 1.0), mode=bilinear)\n",
      "              (conv2): InvertibleModuleWrapper(\n",
      "                (_fn): AdditiveCoupling(\n",
      "                  (Gm): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (Fm): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): InvertibleModuleWrapper(\n",
      "              (_fn): AdditiveCoupling(\n",
      "                (Gm): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (Fm): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down3): CheckpointModule(\n",
      "    (module): Down(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): UpInvertibleBlock(\n",
      "              (upscale): Upsample(scale_factor=(2.0, 1.0), mode=bilinear)\n",
      "              (conv2): InvertibleModuleWrapper(\n",
      "                (_fn): AdditiveCoupling(\n",
      "                  (Gm): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (Fm): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): InvertibleModuleWrapper(\n",
      "              (_fn): AdditiveCoupling(\n",
      "                (Gm): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (Fm): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down4): CheckpointModule(\n",
      "    (module): Down(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): DoubleConv(\n",
      "          (double_conv): Sequential(\n",
      "            (0): InvertibleModuleWrapper(\n",
      "              (_fn): AdditiveCoupling(\n",
      "                (Gm): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (Fm): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): InvertibleModuleWrapper(\n",
      "              (_fn): AdditiveCoupling(\n",
      "                (Gm): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (Fm): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up1): CheckpointModule(\n",
      "    (module): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (conv): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): RestoreClass(StitchableConv2d(in_channel=1024, out_channel=512, kernel=3, stride=1, padding=1, fetch_shape=[128, 128])\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): DownInvertibleBlock(\n",
      "            (conv2): InvertibleModuleWrapper(\n",
      "              (_fn): AdditiveCoupling(\n",
      "                (Gm): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (Fm): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (down_channel): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up2): CheckpointModule(\n",
      "    (module): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (conv): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): DownInvertibleBlock(\n",
      "            (conv2): InvertibleModuleWrapper(\n",
      "              (_fn): AdditiveCoupling(\n",
      "                (Gm): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (Fm): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (down_channel): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): DownInvertibleBlock(\n",
      "            (conv2): InvertibleModuleWrapper(\n",
      "              (_fn): AdditiveCoupling(\n",
      "                (Gm): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (Fm): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (down_channel): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up3): CheckpointModule(\n",
      "    (module): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (conv): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): DownInvertibleBlock(\n",
      "            (conv2): InvertibleModuleWrapper(\n",
      "              (_fn): AdditiveCoupling(\n",
      "                (Gm): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (Fm): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (down_channel): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): DownInvertibleBlock(\n",
      "            (conv2): InvertibleModuleWrapper(\n",
      "              (_fn): AdditiveCoupling(\n",
      "                (Gm): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (Fm): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (down_channel): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up4): CheckpointModule(\n",
      "    (module): Up(\n",
      "      (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (conv): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): DownInvertibleBlock(\n",
      "            (conv2): InvertibleModuleWrapper(\n",
      "              (_fn): AdditiveCoupling(\n",
      "                (Gm): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (Fm): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              )\n",
      "            )\n",
      "            (down_channel): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): InvertibleModuleWrapper(\n",
      "            (_fn): AdditiveCoupling(\n",
      "              (Gm): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (Fm): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (outc): OutConv(\n",
      "    (conv): DownInvertibleBlock(\n",
      "      (conv2): InvertibleModuleWrapper(\n",
      "        (_fn): AdditiveCoupling(\n",
      "          (Gm): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (Fm): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (down_channel): MaxPool3d(kernel_size=(64, 1, 1), stride=(64, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#InvertCnnConverter.top_forward_to_checkpoint(plain_model, last_module_name='outc')\n",
    "InvertCnnConverter.convert_module(plain_model, last_module_name='outc', inplace=True)\n",
    "invert_model = plain_model\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "invert_model = invert_model.to(device)\n",
    "data = image.view(-1,1,320,320).to(device)\n",
    "target = target.to(device)\n",
    "\n",
    "print(invert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoreClass move forward/backward tensor from cpu to cuda:0\n",
      "\tof layer(StitchableConv2d(in_channel=1024, out_channel=512, kernel=3, stride=1, padding=1, fetch_shape=[128, 128])\n",
      "# [start] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=612 / 1315 MB, reserved=1342 / 1342 MB \n",
      "# [end  ] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=612 / 1315 MB, reserved=1342 / 1342 MB \n",
      "0 10.393229484558105\n",
      "# [start] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3331 MB, reserved=4220 / 4220 MB \n",
      "# [end  ] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3331 MB, reserved=4220 / 4220 MB \n",
      "1 10.27920913696289\n",
      "# [start] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "# [end  ] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "2 10.16938304901123\n",
      "# [start] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "# [end  ] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "3 10.063581466674805\n",
      "# [start] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "# [end  ] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "4 9.961552619934082\n",
      "# [start] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "# [end  ] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "5 9.86303997039795\n",
      "# [start] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "# [end  ] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "6 9.767816543579102\n",
      "# [start] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "# [end  ] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "7 9.675629615783691\n",
      "# [start] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "# [end  ] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "8 9.586263656616211\n",
      "# [start] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "# [end  ] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "9 9.499439239501953\n",
      "# [start] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "# [end  ] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "10 9.41494083404541\n",
      "# [start] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "# [end  ] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "11 9.332601547241211\n",
      "# [start] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "# [end  ] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "12 9.252256393432617\n",
      "# [start] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n",
      "# [end  ] StitchableConv2dFunction.forward: stitching\n",
      "  alloc=616 / 3335 MB, reserved=4220 / 4220 MB \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dc4987d7d0a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/memcnn/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/memcnn/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optim = torch.optim.Adam(invert_model.parameters(), lr=1e-3)\n",
    "with torch.autograd.set_detect_anomaly(True) : \n",
    "    for epoch in range(1000) : \n",
    "        result = invert_model(data)\n",
    "        loss = criterion(result, target)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(epoch, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memcrnn",
   "language": "python",
   "name": "memcrnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
